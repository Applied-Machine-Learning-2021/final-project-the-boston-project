{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main (LiDAR and point cloud testing)",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHvakVKxsfZa"
      },
      "source": [
        "Code for UAV lab project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JE9_MC5rc-5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from json import loads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKEFUbTlsk3_"
      },
      "source": [
        "Methods used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR_DDj4Crnh6"
      },
      "source": [
        "def open_lidar(filename, verbose=False):\n",
        "    \"\"\"Method for opening LiDAR text files and handling possible line errors\n",
        "    \"\"\"\n",
        "    # open file and read in each line\n",
        "    with open(filename, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # iterate through lines to cast to lists of floats\n",
        "    new_lines = list()\n",
        "    for line in lines:\n",
        "\n",
        "        # in case file is corrupt \n",
        "        try:\n",
        "            new_lines.append([float(val) for val in line.split()])\n",
        "\n",
        "        except Exception as e:\n",
        "            if verbose:  # printing only if verbose, ignore otherwise\n",
        "                print(line)\n",
        "\n",
        "    # convert nested list to pandas dataframe\n",
        "    new_lines = pd.DataFrame(new_lines)\n",
        "    new_lines = new_lines.rename(columns={0: \"x\", 1: \"y\", 2: \"z\"})\n",
        "\n",
        "    return new_lines\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm6xOU1psolL"
      },
      "source": [
        "Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxs1ieoysLN2"
      },
      "source": [
        "# open and import sample dataset\n",
        "lidar_df = open_lidar(\"N092E301.txt\", True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWUOGji18_qQ"
      },
      "source": [
        "# save out a small number of data points for testing\n",
        "with open(\"N092E301_small.json\", \"w\") as fh:\n",
        "  fh.write(lidar_df[:128].to_json())\n",
        "  fh.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4aJRUhAs8hY"
      },
      "source": [
        "#calculated the max values, the min, the scale(max-min) and the median value \n",
        "max = lidar_df.max() \n",
        "min = lidar_df.min()\n",
        "\n",
        "# organized the data into a list to be converted into a dataframe  \n",
        "lidar_stats = pd.DataFrame(\n",
        "    [min, max, max - min],\n",
        "    index=[\"min\", \"max\", \"scale\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozLxe51qvIHl"
      },
      "source": [
        "# export stats dataframe so the full dataset doesn't have to be loaded everytime this analysis is performed\n",
        "with open(\"N092E301_stats.json\", \"w\") as fh:\n",
        "  fh.write(lidar_stats.to_json())\n",
        "  fh.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS8mf0_WGZSO"
      },
      "source": [
        "# import stats dataframe\n",
        "with open(\"N092E301_stats.json\", \"r\") as fh:\n",
        "  lidar_stats = pd.DataFrame(loads(fh.read()))\n",
        "  fh.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypFD0MsR1FDI"
      },
      "source": [
        "Create Grid DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtoNXQMY1FTQ"
      },
      "source": [
        "side = 2048\n",
        "increment = side / lidar_stats.loc[\"scale\"]\n",
        "point_grid = pd.DataFrame(\n",
        "    index=[y for y in np.arange(lidar_stats[\"y\"][\"min\"], lidar_stats[\"y\"][\"max\"], increment[\"y\"])],\n",
        "    columns=[x for x in np.arange(lidar_stats[\"x\"][\"min\"], lidar_stats[\"x\"][\"max\"], increment[\"x\"])],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOwIEFkM5QIg",
        "outputId": "6757eb7b-6584-498e-c0f4-9b3389cfaedc"
      },
      "source": [
        "print(lidar_stats)\n",
        "print(increment)\n",
        "print(point_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                x           y        z\n",
            "min    5280000.00  3900000.01   327.73\n",
            "max    5284999.99  3905000.00  5633.83\n",
            "scale     4999.99     4999.99  5306.10\n",
            "x    0.409601\n",
            "y    0.409601\n",
            "z    0.385971\n",
            "Name: scale, dtype: float64\n",
            "             5.280000e+06 5.280000e+06  ... 5.284999e+06 5.285000e+06\n",
            "3.900000e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.900000e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.900001e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.900001e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.900002e+06          NaN          NaN  ...          NaN          NaN\n",
            "...                   ...          ...  ...          ...          ...\n",
            "3.904998e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.904998e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.904999e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.904999e+06          NaN          NaN  ...          NaN          NaN\n",
            "3.905000e+06          NaN          NaN  ...          NaN          NaN\n",
            "\n",
            "[12207 rows x 12207 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzpk6Sh67Yq_"
      },
      "source": [
        "Grid LiDAR Data Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "pUCrWcIOY9R_",
        "outputId": "8e4d7941-67a2-43dc-b922-f631feeec7b9"
      },
      "source": [
        "#This function will help form a LiDAR grid with a proper set of consistent points\n",
        "def calc_elevation(x, y, nearby_data_points):\n",
        "  \"\"\"Helper method for calculating the elevation based off nearby points.\n",
        "  \"\"\"\n",
        "\n",
        "  # if not nearby_data_points:\n",
        "  #   return None\n",
        "\n",
        "  distances = [((val[0] - x)**2 + (val[1] - y)**2)**0.5 for val in nearby_data_points]\n",
        "  total_distance = len(distances)\n",
        "  return sum([val[2] * (distances[index]/total_distance) for index, val in enumerate(nearby_data_points)])\n",
        "\n",
        "\n",
        "gridded_df = pd.DataFrame(columns=np.arange(lidar_stats[\"x\"][\"min\"], lidar_stats[\"x\"][\"max\"], increment[\"x\"]))\n",
        "\n",
        "for x in np.arange(lidar_stats[\"x\"][\"min\"], lidar_stats[\"x\"][\"max\"], increment[\"x\"]):\n",
        "  for y in np.arange(lidar_stats[\"y\"][\"min\"], lidar_stats[\"y\"][\"max\"], increment[\"y\"]):\n",
        "    values = lidar_df[\n",
        "                  \n",
        "                      (lidar_df[\"x\"] >= x) & \\\n",
        "                      (lidar_df[\"x\"] <= (x + increment[\"x\"])) & \\\n",
        "                      (lidar_df[\"y\"] >= y) & \\\n",
        "                      (lidar_df[\"y\"] <= (y + increment[\"y\"]))\n",
        "                      ]\n",
        "    delete_indexes = values.index\n",
        "    lidar_df.drop(labels=delete_indexes, axis=0, inplace=True)\n",
        "\n",
        "    \n",
        "    gridded_df[x][y] = calc_elevation(x, y, values.values)\n",
        "\n",
        "    # if the values are less than both the y and x value delete them from the array (reduces computation time A LOT!)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m#  (xint or xbool) and (yint or bool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/roperator.py\u001b[0m in \u001b[0;36mrand_\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrand_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mand_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'bitwise_and' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             except (\n",
            "\u001b[0;32mpandas/_libs/ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_binop\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'double'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-4371c3d8faea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     values = lidar_df[\n\u001b[1;32m     18\u001b[0m                       \u001b[0mlidar_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                       \u001b[0mlidar_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                       \u001b[0mlidar_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                       \u001b[0mlidar_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         result = ops.maybe_dispatch_ufunc_to_dunder_op(\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogical_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mlogical_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mfiller\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_int\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_self_int_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfill_bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_logical_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;34mf\"Cannot perform '{op.__name__}' with a dtyped [{x.dtype}] array \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;34mf\"and scalar of type [{typ}]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 ) from err\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot perform 'rand_' with a dtyped [float64] array and scalar of type [bool]"
          ]
        }
      ]
    }
  ]
}